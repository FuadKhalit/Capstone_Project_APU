{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     C:\\Users\\Fuad\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "#Declaring variable for sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# stock market lexicon\n",
    "stock_lex = pd.read_csv('stock_lex.csv')\n",
    "stock_lex['sentiment'] = (stock_lex['Aff_Score'] + stock_lex['Neg_Score'])/2\n",
    "stock_lex = dict(zip(stock_lex.Item, stock_lex.sentiment))\n",
    "stock_lex = {k:v for k,v in stock_lex.items() if len(k.split(' '))==1}\n",
    "stock_lex_scaled = {}\n",
    "for k, v in stock_lex.items():\n",
    "    if v > 0:\n",
    "        stock_lex_scaled[k] = v / max(stock_lex.values()) * 4\n",
    "    else:\n",
    "        stock_lex_scaled[k] = v / min(stock_lex.values()) * -4\n",
    "\n",
    "# # Loughran and McDonald\n",
    "# positive = []\n",
    "# with open('lexicon_data/lm_positive.csv', 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     for row in reader:\n",
    "#         positive.append(row[0].strip())\n",
    "    \n",
    "# negative = []\n",
    "# with open('lexicon_data/lm_negative.csv', 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     for row in reader:\n",
    "#         entry = row[0].strip().split(\" \")\n",
    "#         if len(entry) > 1:\n",
    "#             negative.extend(entry)\n",
    "#         else:\n",
    "#             negative.append(entry[0])\n",
    "\n",
    "final_lex = {}\n",
    "# final_lex.update({word:2.0 for word in positive})\n",
    "# final_lex.update({word:-2.0 for word in negative})\n",
    "final_lex.update(stock_lex_scaled)\n",
    "final_lex.update(sia.lexicon)\n",
    "sia.lexicon = final_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = urlopen('https://www.businesstimes.com.sg/search/brahim?page=').read()\n",
    "soup = BeautifulSoup(page, features=\"html.parser\")\n",
    "posts = soup.findAll(\"div\", {\"class\": \"media-body\"})# find the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"SATS Ltd has lobbed a conditional binding offer on Wednesday to buy a 49 per cent stake in a Malaysian airline catering firm from Bursa Malaysia-listed Brahim's Holdings Berhad for RM218 million (S$71 million). \""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#headers_30 = [i.text for i in soup.find_all(\"div\", {\"class\":\"media-body\"})]\n",
    "for setr in posts:\n",
    "    wort=setr.find(\"p\").text\n",
    "wort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8073"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "sentiment = sia.polarity_scores(wort)['compound']\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}